{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpHAZd05GsBR",
        "outputId": "68495640-5aa6-4b02-f316-499abe98758f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: LR=0.00100 | Train Loss=0.4530, Acc=0.860 | Val Loss=0.1081, Acc=0.967\n",
            "Epoch 2: LR=0.00100 | Train Loss=0.1379, Acc=0.960 | Val Loss=0.0704, Acc=0.979\n",
            "Epoch 3: LR=0.00100 | Train Loss=0.1004, Acc=0.970 | Val Loss=0.0599, Acc=0.982\n",
            "Epoch 4: LR=0.00100 | Train Loss=0.0819, Acc=0.976 | Val Loss=0.0507, Acc=0.985\n",
            "Epoch 5: LR=0.00050 | Train Loss=0.0700, Acc=0.979 | Val Loss=0.0464, Acc=0.987\n",
            "Epoch 6: LR=0.00050 | Train Loss=0.0552, Acc=0.984 | Val Loss=0.0407, Acc=0.988\n",
            "Epoch 7: LR=0.00050 | Train Loss=0.0484, Acc=0.986 | Val Loss=0.0418, Acc=0.988\n",
            "Epoch 8: LR=0.00050 | Train Loss=0.0458, Acc=0.986 | Val Loss=0.0411, Acc=0.988\n",
            "Epoch 9: LR=0.00050 | Train Loss=0.0416, Acc=0.987 | Val Loss=0.0404, Acc=0.989\n",
            "Epoch 10: LR=0.00025 | Train Loss=0.0387, Acc=0.988 | Val Loss=0.0410, Acc=0.989\n",
            "Epoch 11: LR=0.00025 | Train Loss=0.0350, Acc=0.989 | Val Loss=0.0387, Acc=0.990\n",
            "Epoch 12: LR=0.00025 | Train Loss=0.0308, Acc=0.991 | Val Loss=0.0387, Acc=0.990\n",
            "Epoch 13: LR=0.00025 | Train Loss=0.0292, Acc=0.991 | Val Loss=0.0392, Acc=0.990\n",
            "Epoch 14: LR=0.00025 | Train Loss=0.0266, Acc=0.992 | Val Loss=0.0401, Acc=0.990\n",
            "Epoch 15: LR=0.00013 | Train Loss=0.0263, Acc=0.992 | Val Loss=0.0390, Acc=0.990\n",
            "Epoch 16: LR=0.00013 | Train Loss=0.0232, Acc=0.993 | Val Loss=0.0381, Acc=0.991\n",
            "Epoch 17: LR=0.00013 | Train Loss=0.0214, Acc=0.993 | Val Loss=0.0384, Acc=0.991\n",
            "Epoch 18: LR=0.00013 | Train Loss=0.0224, Acc=0.993 | Val Loss=0.0389, Acc=0.991\n",
            "Epoch 19: LR=0.00013 | Train Loss=0.0219, Acc=0.993 | Val Loss=0.0376, Acc=0.991\n",
            "Epoch 20: LR=0.00006 | Train Loss=0.0205, Acc=0.994 | Val Loss=0.0393, Acc=0.991\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Required Packages\n",
        "!pip install -q onnx onnxruntime\n",
        "\n",
        "# Step 2: Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 3: Dataset Load and Normalization\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "\n",
        "train_size = int(0.67 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=128)\n",
        "\n",
        "# Step 4: CNN Model\n",
        "class DigitClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3),        # -> (26, 26, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),            # -> (13, 13, 32)\n",
        "            nn.Conv2d(32, 64, 3),       # -> (11, 11, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),            # -> (5, 5, 64)\n",
        "            nn.Flatten(),               # -> (1600)\n",
        "            nn.Linear(1600, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)          # -> Output logits\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DigitClassifier().to(device)\n",
        "\n",
        "# Step 5: Training Parameters\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epochs = 20\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Step 6: Training Loop with Scheduler\n",
        "def train_epoch(loader):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = loss_fn(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_epoch(train_loader)\n",
        "    val_loss, val_acc = evaluate(val_loader)\n",
        "    scheduler.step()  # Learning rate updated every epoch\n",
        "    print(f\"Epoch {epoch+1}: LR={scheduler.get_last_lr()[0]:.5f} | Train Loss={train_loss:.4f}, Acc={train_acc:.3f} | Val Loss={val_loss:.4f}, Acc={val_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Exporting Model to ONNX Format ---\n",
        "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "onnx_file = \"mnist_cnn_model.onnx\"\n",
        "torch.onnx.export(model, dummy_input, onnx_file, input_names=[\"input\"], output_names=[\"output\"], opset_version=11)\n",
        "print(f\"Saved model to: {onnx_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-CHQ6V2HO4d",
        "outputId": "15192fcb-4fd1-48de-da39-f8f0388018c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: mnist_cnn_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8: Loading and Test ONNX Model on Random Samples ---\n",
        "# Loading the ONNX model\n",
        "onnx_session = ort.InferenceSession(onnx_file)\n",
        "input_name = onnx_session.get_inputs()[0].name\n",
        "\n",
        "# test data and run prediction\n",
        "sample_images, sample_labels = next(iter(val_loader))\n",
        "sample_image = sample_images[0:1].numpy()\n",
        "\n",
        "# ONNX expects float32\n",
        "input_tensor = sample_image.astype(np.float32)\n",
        "onnx_output = onnx_session.run(None, {input_name: input_tensor})[0]\n",
        "predicted_label = np.argmax(onnx_output)\n",
        "\n",
        "# Displaying the image and prediction\n",
        "plt.imshow(sample_image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "6r6OzxaqHT5x",
        "outputId": "ec50a13d-aa8c-4083-d965-fb1712bde28c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}